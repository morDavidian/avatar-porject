{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as TF\n",
    "\n",
    "from net import Net\n",
    "from enum import Enum\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from landmarksDataset import LandmarksDataset\n",
    "import matplotlib.pyplot as plt # used for visualization and plotting\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import torchvision.models\n",
    "import hiddenlayer as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modes(Enum):\n",
    "    TRAIN = 'train'\n",
    "    TEST = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataByMinMax(data, mins=None, maxs=None):\n",
    "    min_history = []\n",
    "    max_history = []\n",
    "\n",
    "    for i in range(data.shape[1]):\n",
    "        # Compute standard deviation\n",
    "        if (maxs is None or mins is None):\n",
    "            min_val = torch.min(data[:, i])\n",
    "            max_val = torch.max(data[:, i])\n",
    "        else:\n",
    "            min_val = mins[i]\n",
    "            max_val = maxs[i]\n",
    "\n",
    "        denominator = max_val - min_val\n",
    "        denominator = 1e-7 if denominator == 0 else denominator\n",
    "\n",
    "        # Save the min and max history for denormalize later\n",
    "        min_history.append(min_val)\n",
    "        max_history.append(max_val)\n",
    "\n",
    "        # Normalize the data\n",
    "        data[:, i] = (data[:, i] - min_val) / denominator\n",
    "        \n",
    "    history = (min_history, max_history)\n",
    "    return data, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataByStdMean(data, stds=None, means=None):\n",
    "    std_history = []\n",
    "    mean_history = []\n",
    "\n",
    "    for i in range(data.shape[1]):\n",
    "        # Compute standard deviation\n",
    "        if (stds is None or means is None):\n",
    "            std = torch.std(data[:, i])\n",
    "            mean = torch.mean(data[:, i])\n",
    "        else:\n",
    "            std = stds[i]\n",
    "            mean = means[i]\n",
    "\n",
    "        std = 1e-7 if std == 0 else std\n",
    "\n",
    "        # Save the std and mean history for denormalize later\n",
    "        std_history.append(std)\n",
    "        mean_history.append(mean)\n",
    "\n",
    "        # Normalize the data\n",
    "        data[:, i] = (data[:, i] - mean) / std\n",
    "        \n",
    "    history = (std_history, mean_history)\n",
    "    return data, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromCSV(mode, file, start, end):\n",
    "    return pd.read_csv(f'{config.samples_path}\\\\{mode}\\\\{file}',\n",
    "                               usecols = range(start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(mode, x_history=None, y_history=None):\n",
    "    # Get data from csv files\n",
    "    x = getDataFromCSV(mode, config.x_data_file, \n",
    "                        config.x_cols_start_index, config.x_cols_end_index)\n",
    "                        \n",
    "    y = getDataFromCSV(mode, config.y_data_file, \n",
    "                        config.y_cols_start_index, config.y_cols_end_index)\n",
    "\n",
    "    # Transforms the data to tensors\n",
    "    x_tensor = torch.tensor(x.values, requires_grad=True, device = device).float()\n",
    "    y_tensor = torch.tensor(y.values, requires_grad=True, device = device).float()\n",
    "\n",
    "    # Normallize the data\n",
    "    norm_x_tensor, x_history = normalizeDataByMinMax(x_tensor, x_history[0] if x_history is not None else None, x_history[1] if x_history is not None else None)\n",
    "    norm_y_tensor, y_history = normalizeDataByMinMax(y_tensor, y_history[0] if y_history is not None else None, y_history[1] if y_history is not None else None)\n",
    "\n",
    "    return norm_x_tensor, norm_y_tensor, x_history, y_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(mode, x_history=None, y_history=None):\n",
    "    x, y, x_history, y_history = getData(mode, x_history, y_history)\n",
    "    return LandmarksDataset(x, y), x_history, y_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, train_loader, net, optimizer, criterion, log_interval, test_loader):\n",
    "    train_loss_history = []\n",
    "    test_loss_history = []\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        start = time()\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            optimizer.zero_grad()\n",
    "            net_out = net(data)\n",
    "            loss = criterion(net_out, target)\n",
    "            epoch_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        _, test_loss = test(test_loader ,net ,criterion)\n",
    "        train_loss = (epoch_loss.item() / len(train_loader.dataset)) * 100\n",
    "        train_loss_history.append(train_loss)\n",
    "        test_loss_history.append(test_loss)\n",
    "        print(f'Epoch {epoch + 1} summary- train: {train_loss :.5f} test: {test_loss :.5f} took {time()-start:.2f}secs')\n",
    "    return net, train_loss_history, test_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, net, criterion):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        # correct = 0\n",
    "        results = torch.tensor([], device = device).float()\n",
    "\n",
    "        for data, target in test_loader:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            net_out = net(data)\n",
    "            results = torch.cat((results, net_out))\n",
    "            # sum up batch loss\n",
    "            loss = criterion(net_out, target)\n",
    "            test_loss += loss\n",
    "\n",
    "    return results, (test_loss.item() / len(test_loader.dataset)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureSize(data, target):\n",
    "    # Convert tensors to numpy\n",
    "    data, target = data.cpu().detach().numpy(), target.cpu().detach().numpy()\n",
    "    return data.shape[0], target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalizeDataByMinMax(data, min_history, max_history):\n",
    "    for i in range(data.shape[1]):\n",
    "        min_val, max_val = min_history[i], max_history[i]\n",
    "        data[:, i] = (data[:, i] * (max_val - min_val)) + min_val\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalizeDataByStdMean(data, std_history, mean_history):\n",
    "    for i in range(data.shape[1]):\n",
    "        std, mean = std_history[i], mean_history[i]\n",
    "        data[:, i] = (data[:, i] * std) + mean\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateClipAndFrameCols(results):\n",
    "    clips = []\n",
    "    frames = []\n",
    "    loop_num = results.shape[0] // config.frame_num\n",
    "    remaining_div = results.shape[0] % config.frame_num\n",
    "\n",
    "    for i in range(loop_num):\n",
    "        clips = np.concatenate((clips, np.full((1, config.frame_num), str(i))), axis=None)\n",
    "        str_num_range = [*map(str, range(config.frame_num))]\n",
    "        frames = np.concatenate((frames, str_num_range), axis=None)\n",
    "\n",
    "    # Add the remaining rows, if the csv file not contains exactly rows num that divide by frame_num   \n",
    "    if (remaining_div != 0):\n",
    "        clips = np.concatenate((clips, np.full((1, remaining_div), str(loop_num))), axis=None)\n",
    "        str_num_range = [*map(str, range(remaining_div))]\n",
    "        frames = np.concatenate((frames, str_num_range), axis=None)\n",
    "    \n",
    "    # Insert the clip & frame data to the results\n",
    "    results = np.insert(results, 0, clips, axis=1)\n",
    "    results = np.insert(results, 1, frames, axis=1)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveResultsToOutputFile(mode, filename, results):\n",
    "    # Create the output csv columns\n",
    "    blend_cols = []\n",
    "    clip_and_frame_cols = ['clip', 'frame']\n",
    "    quat_cols = ['Quaternion_x', 'Quaternion_y', 'Quaternion_z', 'Quaternion_w']\n",
    "    for i in range(config.blend_range[0], config.blend_range[1]):\n",
    "        blend_cols.append('Blendshape_{0}'.format(i))\n",
    "    output_cols = clip_and_frame_cols + quat_cols + blend_cols\n",
    "    \n",
    "    # Convert the results to from tensor to numpy \n",
    "    results = results.cpu().detach().numpy()\n",
    "\n",
    "    # Generate and insert clip & frame columns\n",
    "    results = generateClipAndFrameCols(results)\n",
    "\n",
    "    # Convert the results to data frame\n",
    "    results = pd.DataFrame(results, columns=output_cols)\n",
    "\n",
    "    # Convert columns data type from float to int\n",
    "    results['clip'] = results['clip'].astype(int)\n",
    "    results['frame'] = results['frame'].astype(int)\n",
    "    \n",
    "    # Assign values outside boundary to boundary values\n",
    "    results.loc[:, quat_cols] = results.loc[:, quat_cols].clip(config.quat_domain[0], config.quat_domain[1])\n",
    "    results.loc[:, blend_cols] = results.loc[:, blend_cols].clip(config.blend_domain[0], config.blend_domain[1])\n",
    "\n",
    "    # Save the results to the output csv file\n",
    "    file_path = f'{config.samples_path}\\\\{mode}\\\\{filename}'\n",
    "    results.to_csv(file_path, index=False)\n",
    "    print(f'[{datetime.now()}] Successfully saved the results to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    epochs=50\n",
    "    batch_size=256\n",
    "    log_interval=10\n",
    "    learning_rate=1e-3\n",
    "    \n",
    "    print(f'The device used is {device}')\n",
    "\n",
    "    # Create the train data loader\n",
    "    train_dataset, x_history, y_history = getDataset(Modes.TRAIN.value)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size,\n",
    "        shuffle=False)\n",
    "    # Create the test data loader\n",
    "    test_dataset, _, _ = getDataset(Modes.TEST.value, x_history, y_history)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size,\n",
    "        shuffle=False)\n",
    "\n",
    "    # Extract the input and output num of features\n",
    "    in_num_of_features, out_num_of_features = getFeatureSize(*train_dataset[0])\n",
    "\n",
    "    # Create the net\n",
    "    net = Net(in_num_of_features, out_num_of_features)\n",
    "    net.to(device)\n",
    "    print(net)\n",
    "\n",
    "    # Create an optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Create a loss function\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "\n",
    "    # Run the main training loop\n",
    "    net, train_loss_history, test_loss_history = train(epochs, train_loader, net, optimizer, criterion, log_interval, test_loader)\n",
    "                \n",
    "    # Run a test loop\n",
    "    results, test_loss = test(test_loader, net, criterion)\n",
    "    \n",
    "    # De-normalize the data to the original domains\n",
    "    results = denormalizeDataByMinMax(results, *y_history)\n",
    "    \n",
    "    # Save the results to output file\n",
    "    saveResultsToOutputFile(Modes.TEST.value, config.output_filename, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(name, loss_history):\n",
    "    plt.plot(np.arange(epochs) ,loss_history)\n",
    "    plt.title(name, fontsize=16)\n",
    "    plt.xlabel('epoch', fontsize=16)\n",
    "    plt.ylabel('loss', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "visualize_loss(\"Train Loss\",train_loss_history)\n",
    "visualize_loss(\"Test Loss\", test_loss_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
